{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1083.049072265625\n",
      "199 758.2042236328125\n",
      "299 531.9873657226562\n",
      "399 374.3208923339844\n",
      "499 264.3468017578125\n",
      "599 187.580322265625\n",
      "699 133.9552001953125\n",
      "799 96.46939849853516\n",
      "899 70.2479476928711\n",
      "999 51.894378662109375\n",
      "1099 39.04008865356445\n",
      "1199 30.032033920288086\n",
      "1299 23.715879440307617\n",
      "1399 19.284881591796875\n",
      "1499 16.174793243408203\n",
      "1599 13.990854263305664\n",
      "1699 12.456541061401367\n",
      "1799 11.378170013427734\n",
      "1899 10.619937896728516\n",
      "1999 10.08659839630127\n",
      "Result: y = -0.036353595554828644 + 0.8659560084342957 x + 0.006271598860621452 x^2 + -0.09464116394519806 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "dtype = torch.float\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "# Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1876.3504638671875\n",
      "199 1253.8363037109375\n",
      "299 839.2432861328125\n",
      "399 563.0013427734375\n",
      "499 378.85565185546875\n",
      "599 256.0414733886719\n",
      "699 174.08920288085938\n",
      "799 119.37342071533203\n",
      "899 82.82135009765625\n",
      "999 58.38847732543945\n",
      "1099 42.04633331298828\n",
      "1199 31.1084041595459\n",
      "1299 23.782678604125977\n",
      "1399 18.87261390686035\n",
      "1499 15.579191207885742\n",
      "1599 13.36843204498291\n",
      "1699 11.883232116699219\n",
      "1799 10.884614944458008\n",
      "1899 10.212570190429688\n",
      "1999 9.75991439819336\n",
      "Result: y = -0.018499277532100677 + 0.8322007060050964 x + 0.003191431052982807 x^2 + -0.08983977138996124 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "# Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)  #这个是因为对某一个y_prded求导\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集比较小时，gpu的速度不一定比cpu快，得数据集有一定大小时才能体现gpu的优势"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
